import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score,␣
↪f1_score, roc_auc_score
from imblearn.over_sampling import SMOTE
# Task 1: Data Exploration and Preprocessing
# Load the dataset
df = pd.read_csv("/content/creditcard.csv")
# Display the first few rows and column names
print(df.head())
print(df.columns)
# Check for missing values
print(df.isnull().sum())
# Handle missing values (if any)
df = df.fillna(df.mean()) # Example for numeric columns
# Ensure 'Class' column is treated as categorical (integer) if not already
df['Class'] = df['Class'].astype(int)
# Visualize the distribution of classes
fraud_counts = df['Class'].value_counts()
plt.figure(figsize=(8, 6))
plt.bar(fraud_counts.index, fraud_counts.values, color=['blue', 'red'])
plt.xticks([0, 1], ['Non-Fraudulent', 'Fraudulent'])
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Distribution of Classes')
plt.show()
# Task 2: Baseline Model Training
# Split the dataset into training and testing sets

1

X = df.drop('Class', axis=1) # Features
y = df['Class'] # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,␣
↪random_state=42)
# Train a baseline Logistic Regression model
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
# Evaluate baseline model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)
print(f'Baseline Model Metrics:')
print(f'Accuracy: {accuracy:.2f}')
print(f'Precision: {precision:.2f}')
print(f'Recall: {recall:.2f}')
print(f'F1-score: {f1:.2f}')
print(f'ROC AUC: {roc_auc:.2f}')
# Task 3: Handling Class Imbalance
# Apply SMOTE to balance the training data
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
# Train Logistic Regression model on balanced data
model_balanced = LogisticRegression(random_state=42)
model_balanced.fit(X_train_resampled, y_train_resampled)
y_pred_balanced = model_balanced.predict(X_test)
# Evaluate balanced model
accuracy_balanced = accuracy_score(y_test, y_pred_balanced)
precision_balanced = precision_score(y_test, y_pred_balanced)
recall_balanced = recall_score(y_test, y_pred_balanced)
f1_balanced = f1_score(y_test, y_pred_balanced)
roc_auc_balanced = roc_auc_score(y_test, y_pred_balanced)
print(f'Balanced Model Metrics:')
print(f'Accuracy: {accuracy_balanced:.2f}')
print(f'Precision: {precision_balanced:.2f}')
print(f'Recall: {recall_balanced:.2f}')
print(f'F1-score: {f1_balanced:.2f}')
print(f'ROC AUC: {roc_auc_balanced:.2f}')
# Task 4: Advanced Techniques and Final Evaluation

2

# You can continue with additional techniques and models here.
# Task 5: Summary of Findings
# Summarize your results and discuss the impact of different techniques on␣
↪model performance.
Time V1 V2 V3 V4 V5 V6 V7 \
0 0.0 -1.359807 -0.072781 2.536347 1.378155 -0.338321 0.462388 0.239599
1 0.0 1.191857 0.266151 0.166480 0.448154 0.060018 -0.082361 -0.078803
2 1.0 -1.358354 -1.340163 1.773209 0.379780 -0.503198 1.800499 0.791461
3 1.0 -0.966272 -0.185226 1.792993 -0.863291 -0.010309 1.247203 0.237609
4 2.0 -1.158233 0.877737 1.548718 0.403034 -0.407193 0.095921 0.592941
V8 V9 ... V21 V22 V23 V24 V25 \
0 0.098698 0.363787 ... -0.018307 0.277838 -0.110474 0.066928 0.128539
1 0.085102 -0.255425 ... -0.225775 -0.638672 0.101288 -0.339846 0.167170
2 0.247676 -1.514654 ... 0.247998 0.771679 0.909412 -0.689281 -0.327642
3 0.377436 -1.387024 ... -0.108300 0.005274 -0.190321 -1.175575 0.647376
4 -0.270533 0.817739 ... -0.009431 0.798278 -0.137458 0.141267 -0.206010
V26 V27 V28 Amount Class
0 -0.189115 0.133558 -0.021053 149.62 0.0
1 0.125895 -0.008983 0.014724 2.69 0.0
2 -0.139097 -0.055353 -0.059752 378.66 0.0
3 -0.221929 0.062723 0.061458 123.50 0.0
4 0.502292 0.219422 0.215153 69.99 0.0
[5 rows x 31 columns]
Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',
'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',
'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',
'Class'],
dtype='object')
Time 0
V1 0
V2 0
V3 0
V4 0
V5 0
V6 0
V7 0
V8 0
V9 0
V10 1
V11 1
V12 1
V13 1

3

V14 1
V15 1
V16 1
V17 1
V18 1
V19 1
V20 1
V21 1
V22 1
V23 1
V24 1
V25 1
V26 1
V27 1
V28 1
Amount 1
Class 1
dtype: int64

/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458:
ConvergenceWarning: lbfgs failed to converge (status=1):

4

STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:

https://scikit-learn.org/stable/modules/linear_model.html#logistic-
regression

n_iter_i = _check_optimize_result(
Baseline Model Metrics:
Accuracy: 1.00
Precision: 0.72
Recall: 0.73
F1-score: 0.73
ROC AUC: 0.87
Balanced Model Metrics:
Accuracy: 0.98
Precision: 0.10
Recall: 0.91
F1-score: 0.18
ROC AUC: 0.95
/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458:
ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:

https://scikit-learn.org/stable/modules/linear_model.html#logistic-
regression

n_iter_i = _check_optimize_result(
